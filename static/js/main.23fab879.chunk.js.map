{"version":3,"sources":["App.js","reportWebVitals.js","index.js"],"names":["classifier","objectDetector","url","App","videoRef","useRef","useState","model","setModel","result","setResult","input","setInput","facingMode","setFacingMode","useEffect","startWebcam","ml5","imageClassifier","console","log","setTimeout","classify","current","error","results","detect","a","navigator","mediaDevices","getUserMedia","video","then","stream","srcObject","catch","style","display","flexDirection","alignItems","justifyContent","className","type","onClick","ref","width","window","innerWidth","height","innerHeight","autoPlay","getTracks","forEach","track","stop","prev","undefined","map","item","ind","label","role","confidence","aria-valuenow","toFixed","aria-valuemin","aria-valuemax","reportWebVitals","onPerfEntry","Function","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"2HAGIA,EACAC,E,+FAKAC,EAAK,2DAEM,SAASC,IACtB,IAAMC,EAAWC,mBADW,EAEDC,mBAASJ,GAFR,mBAErBK,EAFqB,KAEbC,EAFa,OAGAF,mBAAS,IAHT,mBAGrBG,EAHqB,KAGbC,EAHa,OAIAJ,oBAAS,GAJT,gCAKHA,mBAAS,IALN,mBAKrBK,EALqB,KAKfC,EALe,OAMON,oBAAS,GANhB,mBAMrBO,EANqB,KAMVC,EANU,KAO5BC,qBAAU,WACRC,IACY,IAATT,EACDC,EAASN,IAETF,EAAaiB,IAAIC,gBAAgBX,GAAO,WACtCY,QAAQC,IAAI,4BAEdnB,EAAiBgB,IAAIhB,eAAeM,GAAM,WACxCY,QAAQC,IAAI,gCAIf,CAACb,IACJQ,qBAAU,WACJf,GAAcC,IACH,IAAVU,EACDU,YAAW,WACTrB,EAAWsB,SAASlB,EAASmB,SAAS,SAACC,EAAOC,GACxCD,EACFL,QAAQK,MAAMA,GAGhBd,EAAUe,QApCR,KAuCW,IAAVd,GACPU,YAAW,WACTpB,EAAeyB,OAAOtB,EAASmB,SAAS,SAACC,EAAOC,GAC3CD,EACDL,QAAQK,MAAMA,GAGhBL,QAAQC,IAAIK,QA9CV,QAuDT,CAAChB,EAAOE,IACX,IAAMK,EAAW,uCAAG,sBAAAW,EAAA,sEACXC,UAAUC,aACZC,aAAa,CAAEC,MAAO,CACrBlB,WAAYA,EAAc,cAAkB,UAE7CmB,MAAK,SAAAC,GAAM,OAAI7B,EAASmB,QAAQW,UAAYD,KAC5CE,MAAMhB,QAAQC,KAND,2CAAH,qDAcjB,OACE,sBAAKgB,MAAO,CAACC,QAAS,OAAOC,cAAc,SAASC,WAAY,SAASC,eAAgB,UAAzF,UACE,qBAAKC,UAAU,OAAf,SACE,wBAAQC,KAAK,SAASD,UAAU,0BAA0BE,QAAS,kBAAM/B,EAAS,IAAlF,8BAGF,uBACEgC,IAAKxC,EACLyC,MAAOC,OAAOC,WACdC,OAA2B,IAAnBF,OAAOG,YACfC,UAAQ,EACRP,QAAS,WAhBGvC,EAASmB,QAAQW,UAC1BiB,YAAYC,SAAQ,SAASC,GAClCA,EAAMC,UAcwBxC,GAAc,SAAAyC,GAAI,OAAGA,KAAMvC,OAGxDhB,GAAcS,QAAqB+C,IAAX/C,EACzB,gCACE,wCACCA,EAAOgD,KAAI,SAACC,EAAMC,GAAP,OAAe,8BAAcD,EAAKE,MAE9C,qBAAKnB,UAAU,WAAf,SACA,sBAAKA,UAAU,eAAeoB,KAAK,cAAczB,MAAO,CAACS,MAAuB,IAAhBa,EAAKI,YAAkBC,iBAAgC,IAAhBL,EAAKI,YAAgBE,QAAQ,GAAKC,gBAAc,IAAIC,gBAAc,MAAzK,WAAiM,IAAhBR,EAAKI,YAAgBE,QAAQ,GAA9M,WAHmCL,SAQpC,qDA1FPzD,GAAO,cCVP,IAYeiE,EAZS,SAAAC,GAClBA,GAAeA,aAAuBC,UACxC,6BAAqBrC,MAAK,YAAkD,IAA/CsC,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOF,GACPG,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAQN,OCDdO,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC1E,EAAD,MAEF2E,SAASC,eAAe,SAM1BZ,M","file":"static/js/main.23fab879.chunk.js","sourcesContent":["import React, { useEffect, useRef, useState } from \"react\";\nimport ml5 from \"ml5\";\n\nlet classifier;\nlet objectDetector;\nconst delay = 300\n// const url = \"https://teachablemachine.withgoogle.com/models/RrGhF9eh_/model.json\"\n//const url = \"https://teachablemachine.withgoogle.com/models/c5QHqrAOk/model.json\"\n// const url = \"https://teachablemachine.withgoogle.com/models/zvuTPJFzc/model.json\"\nlet url ='https://teachablemachine.withgoogle.com/models/lP8sH70Bi'\nurl += '/model.json'\nexport default function App() {\n  const videoRef = useRef();\n  const [model , setModel] = useState(url)\n  const [result, setResult] = useState([]);\n  const [loaded, setLoaded] = useState(false);\n  const [input,setInput] = useState(0)\n  const [facingMode,setFacingMode] = useState(true)\n  useEffect(() => {\n    startWebcam()\n    if(model == \"\"){\n      setModel(url)\n    }else{\n      classifier = ml5.imageClassifier(model, () => {\n        console.log(\"Image Model is Loaded\")\n      });\n      objectDetector = ml5.objectDetector(model,()=>{\n        console.log(\"object Model is Loaded\")\n      } );\n    }\n     \n  }, [model]);\n  useEffect(() => {\n    if (classifier && objectDetector) {\n      if(input === 0){\n        setTimeout(() => {\n          classifier.classify(videoRef.current, (error, results) => {\n            if (error) {\n              console.error(error);\n              return;\n            }\n            setResult(results);\n          }); \n        }, delay);\n      }else if(input === 1){\n        setTimeout(() => {\n          objectDetector.detect(videoRef.current, (error, results) => {\n            if(error) {\n              console.error(error)\n              return\n            }\n            console.log(results)\n          })\n        }, delay);\n      }else{\n        ;\n        // add more here !\n      }\n     \n    }\n  }, [result,input])\n  const startWebcam = async () =>{\n     await navigator.mediaDevices\n        .getUserMedia({ video: {\n          facingMode: facingMode ?  \"environment\"  :  \"user\" \n        } })\n        .then(stream => videoRef.current.srcObject = stream)\n        .catch(console.log);\n  }\n  const stopWebcam = () =>{\n    const stream =  videoRef.current.srcObject;\n    stream.getTracks().forEach(function(track) {\n      track.stop();\n    });\n  }\n  return (\n    <div style={{display: 'flex',flexDirection:'column',alignItems: 'center',justifyContent: 'center'}}>\n      <div className=\"flex\" >\n        <button type=\"button\" className=\"btn btn-outline-success\" onClick={() => setInput(0)}>Image Classify</button>\n        {/* <button type=\"button\" className=\"btn btn-outline-warning\" onClick={() => {setInput(1);}}>Object Detector</button> */}\n      </div>\n      <video\n        ref={videoRef}\n        width={window.innerWidth}\n        height={window.innerHeight*.75}\n        autoPlay\n        onClick={() =>{stopWebcam();setFacingMode(prev=>!prev);startWebcam()}}\n      ></video> \n      \n      {classifier && result && result !== undefined ? \n      <div >\n        <h1 >Result</h1>\n        {result.map((item, ind) => <p key={ind}>{item.label} \n\n        <div className=\"progress\">\n        <div className=\"progress-bar\" role=\"progressbar\" style={{width:(item.confidence*110)}} aria-valuenow={(item.confidence*100).toFixed(2) } aria-valuemin=\"0\" aria-valuemax=\"100\">{(item.confidence*100).toFixed(2) }%</div>\n        </div>\n        </p>)}\n      </div>\n      \n      :<>Loading...</> }\n      \n    </div>\n  )\n}\n","const reportWebVitals = onPerfEntry => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}