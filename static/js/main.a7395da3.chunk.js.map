{"version":3,"sources":["App.js","reportWebVitals.js","index.js"],"names":["classifier","url","App","videoRef","useRef","useState","model","setModel","result","input","setInput","facingMode","setFacingMode","useEffect","startWebcam","ml5","imageClassifier","console","log","a","navigator","mediaDevices","getUserMedia","video","then","stream","current","srcObject","catch","style","display","flexDirection","alignItems","justifyContent","className","type","onClick","ref","width","window","innerWidth","height","innerHeight","autoPlay","getTracks","forEach","track","stop","prev","undefined","map","item","ind","label","role","confidence","aria-valuenow","toFixed","aria-valuemin","aria-valuemax","reportWebVitals","onPerfEntry","Function","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"2HAGIA,E,gGAQAC,EAAK,4DAIM,SAASC,IACtB,IAAMC,EAAWC,mBADW,EAEDC,mBAASJ,GAFR,mBAErBK,EAFqB,KAEbC,EAFa,OAGAF,mBAAS,IAHT,mBAGrBG,EAHqB,aAIAH,oBAAS,IAJT,gCAKHA,mBAAS,IALN,mBAKrBI,EALqB,KAKfC,EALe,OAMOL,oBAAS,GANhB,mBAMrBM,EANqB,KAMVC,EANU,KAO5BC,qBAAU,WACRC,IACY,IAATR,EACDC,EAASN,GAETD,EAAae,IAAIC,gBAAgBV,GAAO,WACtCW,QAAQC,IAAI,yBACZD,QAAQC,IAAIZ,QAOf,CAACA,IACJO,qBAAU,WA4BRI,QAAQC,IAAIV,KACX,CAACA,EAAOC,IACX,IAAMK,EAAW,uCAAG,sBAAAK,EAAA,sEACXC,UAAUC,aACZC,aAAa,CAAEC,MAAO,CACrBZ,WAAYA,EAAc,cAAkB,UAE7Ca,MAAK,SAAAC,GAAM,OAAItB,EAASuB,QAAQC,UAAYF,KAC5CG,MAAMX,QAAQC,KAND,2CAAH,qDAcjB,OACE,sBAAKW,MAAO,CAACC,QAAS,OAAOC,cAAc,SAASC,WAAY,SAASC,eAAgB,UAAzF,UACE,qBAAKC,UAAU,OAAf,SACE,wBAAQC,KAAK,SAASD,UAAU,0BAA0BE,QAAS,kBAAM1B,EAAS,IAAlF,8BAGF,uBACE2B,IAAKlC,EACLmC,MAAOC,OAAOC,WACdC,OAA2B,IAAnBF,OAAOG,YACfC,UAAQ,EACRP,QAAS,WAhBGjC,EAASuB,QAAQC,UAC1BiB,YAAYC,SAAQ,SAASC,GAClCA,EAAMC,UAcwBnC,GAAc,SAAAoC,GAAI,OAAGA,KAAMlC,OAGxDd,GAAcQ,QAAqByC,IAAXzC,EACzB,gCACE,wCACCA,EAAO0C,KAAI,SAACC,EAAMC,GAAP,OAAe,8BAAcD,EAAKE,MAE9C,qBAAKnB,UAAU,WAAf,SACA,sBAAKA,UAAU,eAAeoB,KAAK,cAAczB,MAAO,CAACS,MAAuB,IAAhBa,EAAKI,YAAkBC,iBAAgC,IAAhBL,EAAKI,YAAgBE,QAAQ,GAAKC,gBAAc,IAAIC,gBAAc,MAAzK,WAAiM,IAAhBR,EAAKI,YAAgBE,QAAQ,GAA9M,WAHmCL,SAQpC,qGA9FPnD,GAAO,aCZP,IAYe2D,EAZS,SAAAC,GAClBA,GAAeA,aAAuBC,UACxC,6BAAqBtC,MAAK,YAAkD,IAA/CuC,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOF,GACPG,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAQN,OCDdO,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAACpE,EAAD,MAEFqE,SAASC,eAAe,SAM1BZ,M","file":"static/js/main.a7395da3.chunk.js","sourcesContent":["import React, { useEffect, useRef, useState } from \"react\";\nimport ml5 from \"ml5\";\n\nlet classifier;\nlet objectDetector;\nconst delay = 300\n// const url = \"https://teachablemachine.withgoogle.com/models/RrGhF9eh_/\"\n// let url = \"https://teachablemachine.withgoogle.com/models/c5QHqrAOk/\"\n// const url = \"https://teachablemachine.withgoogle.com/models/zvuTPJFzc/\"\n// let url ='https://teachablemachine.withgoogle.com/models/lP8sH70Bi/'\n// let url = 'https://teachablemachine.withgoogle.com/models/rxnp5FoT0/'\nlet url ='https://teachablemachine.withgoogle.com/models/ntvbyZsmT/'\nurl += 'model.json'\n// const url = './model.json'\n\nexport default function App() {\n  const videoRef = useRef();\n  const [model , setModel] = useState(url)\n  const [result, setResult] = useState([]);\n  const [loaded, setLoaded] = useState(false);\n  const [input,setInput] = useState(0)\n  const [facingMode,setFacingMode] = useState(true)\n  useEffect(() => {\n    startWebcam()\n    if(model == \"\"){\n      setModel(url)\n    }else{\n      classifier = ml5.imageClassifier(model, () => {\n        console.log(\"Image Model is Loaded\")\n        console.log(model)\n      });\n      // objectDetector = ml5.objectDetector(model,()=>{\n      //   console.log(\"object Model is Loaded\")\n      // } );\n    }\n     \n  }, [model]);\n  useEffect(() => {\n    if (classifier && objectDetector) {\n      if(input === 0){\n        setTimeout(() => {\n          classifier.classify(videoRef.current, (error, results) => {\n            if (error) {\n              console.error(error);\n              return;\n            }\n            setResult(results);\n          }); \n        }, delay);\n      }else if(input === 1){\n        setTimeout(() => {\n          objectDetector.detect(videoRef.current, (error, results) => {\n            if(error) {\n              console.error(error)\n              return\n            }\n            console.log(results)\n          })\n        }, delay);\n      }else{\n        ;\n        // add more here !\n      }\n     \n    }\n    console.log(result)\n  }, [result,input])\n  const startWebcam = async () =>{\n     await navigator.mediaDevices\n        .getUserMedia({ video: {\n          facingMode: facingMode ?  \"environment\"  :  \"user\" \n        } })\n        .then(stream => videoRef.current.srcObject = stream)\n        .catch(console.log);\n  }\n  const stopWebcam = () =>{\n    const stream =  videoRef.current.srcObject;\n    stream.getTracks().forEach(function(track) {\n      track.stop();\n    });\n  }\n  return (\n    <div style={{display: 'flex',flexDirection:'column',alignItems: 'center',justifyContent: 'center'}}>\n      <div className=\"flex\" >\n        <button type=\"button\" className=\"btn btn-outline-success\" onClick={() => setInput(0)}>Image Classify</button>\n        {/* <button type=\"button\" className=\"btn btn-outline-warning\" onClick={() => {setInput(1);}}>Object Detector</button> */}\n      </div>\n      <video\n        ref={videoRef}\n        width={window.innerWidth}\n        height={window.innerHeight*.75}\n        autoPlay\n        onClick={() =>{stopWebcam();setFacingMode(prev=>!prev);startWebcam()}}\n      ></video> \n      \n      {classifier && result && result !== undefined ? \n      <div >\n        <h1 >Result</h1>\n        {result.map((item, ind) => <p key={ind}>{item.label} \n\n        <div className=\"progress\">\n        <div className=\"progress-bar\" role=\"progressbar\" style={{width:(item.confidence*110)}} aria-valuenow={(item.confidence*100).toFixed(2) } aria-valuemin=\"0\" aria-valuemax=\"100\">{(item.confidence*100).toFixed(2) }%</div>\n        </div>\n        </p>)}\n      </div>\n      \n      :<>กำลังโหลด ...</> }\n      \n    </div>\n  )\n}\n","const reportWebVitals = onPerfEntry => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}